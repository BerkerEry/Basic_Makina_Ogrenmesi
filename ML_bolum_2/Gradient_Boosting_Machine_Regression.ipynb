{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faedebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7bd8737",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Hitters.csv\")\n",
    "df = df.dropna()\n",
    "\n",
    "#one-hot encoding\n",
    "dms = pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])\n",
    "\n",
    "y = df[\"Salary\"]\n",
    "X_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis = 1).astype(\"float64\")\n",
    "X = pd.concat([X_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a437b5f",
   "metadata": {},
   "source": [
    "#### Model & Tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cf6af25",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_model = GradientBoostingRegressor().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38223709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GradientBoostingRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">?<span>Documentation for GradientBoostingRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02c5dbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352.0674526325749"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gbm_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edf18f2",
   "metadata": {},
   "source": [
    "#### Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdbeaf48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GradientBoostingRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">?<span>Documentation for GradientBoostingRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model = GradientBoostingRegressor().fit(X_train, y_train)\n",
    "gbm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03e548c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "?gbm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c08c79bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_params = {\"learning_rate\": [0.1, 0.01, 0.001],\n",
    "              \"max_depth\": [3,5,8],\n",
    "              \"n_estimators\": [100, 200, 500],\n",
    "              \"subsample\": [1, 0.5, 0.8],\n",
    "              \"loss\": [\"squared_error\", \"absolute_error\", \"quantile\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b362285",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_model = GradientBoostingRegressor().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8714ca80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 243 candidates, totalling 2430 fits\n",
      "[CV] END learning_rate=0.1, loss=ls, max_depth=3, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=ls, max_depth=3, n_estimators=500, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=ls, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=ls, max_depth=5, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=ls, max_depth=5, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=ls, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=ls, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=ls, max_depth=5, n_estimators=200, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=ls, max_depth=5, n_estimators=200, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=ls, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=ls, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=ls, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=ls, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=ls, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=ls, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=ls, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=ls, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=ls, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=ls, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=ls, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=ls, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=ls, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=ls, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=lad, max_depth=5, n_estimators=200, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=lad, max_depth=5, n_estimators=200, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=lad, max_depth=5, n_estimators=200, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=lad, max_depth=5, n_estimators=200, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=lad, max_depth=5, n_estimators=200, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=lad, max_depth=5, n_estimators=200, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=lad, max_depth=5, n_estimators=200, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=lad, max_depth=5, n_estimators=200, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   5.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   4.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   4.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   4.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   4.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   4.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   5.1s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   4.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   4.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   5.1s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   3.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   3.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   3.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   3.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   2.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=5, n_estimators=200, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=5, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   2.7s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   2.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.1s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   2.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   2.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   2.7s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   3.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   3.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   3.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   3.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   3.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   3.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   3.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   2.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   3.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   3.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   2.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.1s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   2.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   3.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   3.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   2.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END learning_rate=0.001, loss=lad, max_depth=8, n_estimators=500, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   2.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   2.9s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   3.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   3.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   2.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   6.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   4.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   5.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   3.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   2.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   3.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   4.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   6.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   5.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   2.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   3.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   3.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   2.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   6.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   5.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.3s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   4.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   4.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   4.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   4.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   4.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   4.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   4.2s\n",
      "[CV] END learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=ls, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   2.7s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   2.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   3.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   3.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   6.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   4.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   5.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   3.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   3.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   2.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   7.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   5.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   2.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   3.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   6.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   5.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   3.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   4.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.7s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   2.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   3.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   2.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   6.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   4.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   5.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   4.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   3.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   2.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   6.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   4.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   2.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   4.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.7s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   3.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   2.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   6.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   4.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   5.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   4.3s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.7s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   3.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   3.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   6.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   4.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   4.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   4.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   3.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.5s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   2.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   4.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.2s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   6.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   5.2s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   2.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   2.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   4.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   4.1s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   2.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   3.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   3.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   6.5s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   4.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   4.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   5.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   2.1s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   3.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   4.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   4.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.5s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   6.6s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   6.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   2.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   4.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   4.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   6.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   3.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.0s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   4.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.7s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   6.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   4.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   5.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   4.3s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   3.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   5.2s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   2.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   3.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.2s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   4.4s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.9s\n",
      "[CV] END learning_rate=0.1, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   4.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   6.2s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   5.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   6.0s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   5.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.7s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   3.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   6.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   5.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.5s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   2.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   5.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.6s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   3.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   5.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.7s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   5.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.1s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   5.9s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   4.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   4.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   6.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   5.2s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   2.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.1s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   5.2s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   2.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.3s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   3.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   5.0s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   4.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.7s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   4.3s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.2s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   4.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   2.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   4.0s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   4.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   2.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.3s\n"
     ]
    }
   ],
   "source": [
    "gbm_cv_model = GridSearchCV(gbm_model, gbm_params, cv=10, n_jobs=-1, verbose=2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8d3a3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1,\n",
       " 'loss': 'absolute_error',\n",
       " 'max_depth': 3,\n",
       " 'n_estimators': 100,\n",
       " 'subsample': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb536217",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_tuned = GradientBoostingRegressor(learning_rate=0.1,\n",
    "                                      loss = \"absolute_error\",\n",
    "                                      max_depth=3,\n",
    "                                      n_estimators=100,\n",
    "                                      subsample=1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f4292fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329.98158822397744"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gbm_tuned.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aa78ee",
   "metadata": {},
   "source": [
    "#### DeÄŸiÅŸken Ã–nem DÃ¼zeyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "150ec9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.3s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   3.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   4.0s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   4.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   4.2s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   4.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   3.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   4.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   2.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   2.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   2.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   4.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   4.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   2.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.9s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   4.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   5.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   4.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   2.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.1s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.3s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.3s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   4.1s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   4.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   4.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   1.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   3.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   2.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.3s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   3.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   4.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.0s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   4.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   2.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   2.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   4.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   3.1s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   4.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   3.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   3.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.0s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=squared_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=1; total time=   2.5s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=1; total time=   4.2s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.5; total time=   2.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.7s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=1; total time=   1.9s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=1; total time=   5.2s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.8s\n",
      "[CV] END learning_rate=0.001, loss=absolute_error, max_depth=8, n_estimators=500, subsample=0.8; total time=   4.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=1; total time=   2.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=3, n_estimators=500, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=1; total time=   3.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.5s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=1; total time=   3.3s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.5; total time=   2.2s\n",
      "[CV] END learning_rate=0.001, loss=quantile, max_depth=8, n_estimators=500, subsample=0.8; total time=   2.2s\n"
     ]
    }
   ],
   "source": [
    "Importance = pd.DataFrame({\"Importance\": gbm_tuned.feature_importances_*100},\n",
    "                          index = X_train.columns)\n",
    "\n",
    "Importance.sort_values(by = \"Importance\",\n",
    "                           axis = 0,\n",
    "                           ascending = True).plot(kind = \"barh\",\n",
    "                                                  color = \"r\")\n",
    "\n",
    "plt.xlabel(\"Variable Importance\")\n",
    "plt.gca().legend_ = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7055717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyter_env)",
   "language": "python",
   "name": "jupyter_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
